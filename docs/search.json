[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I‚Äôm a data scientist, writer, educator & podcaster. My interests include promoting data & AI literacy/fluency, helping to spread data skills through organizations and society and lowering the barrier to entry for data science, analysis, and machine learning. I‚Äôm currently Head of Developer Relations at Outerbounds, a company committed to building infrastructure that provides a solid foundation for machine learning and AI applications of all shapes and sizes. I am also the host of the industry podcast Vanishing Gradients. Find out more here."
  },
  {
    "objectID": "posts/llm-productivity/index.html",
    "href": "posts/llm-productivity/index.html",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "",
    "text": "Tl;dr\nLarge Language Models (LLMs), such as ChatGPT and Claude, are known for their text generation and conversational abilities. But they are also good at other tasks that can help time-starved non-technical working professionals save time, such as text summarization and analysis.\nHave a 60-page PDF you don‚Äôt have time to read and want summarized? A meeting you need action items from? Or an online video you need transcribed and summarized? Would you like them to then generate a PDF, text file, or spreadsheet of the results?\nChatGPT will do these tasks for you. It can also do market research, competitive analyses, email drafting, ad campaign ideation, and much more. This blog post will take you through many such examples, including relevant conversations with ChatGPT: the goal is to give you the tools to get LLMs to do what they‚Äôre good at, freeing you up to do what you‚Äôre good at.\nNote: I used GPT-4 in ChatGPT for much of this post. If I were to rewrite it (which I might), I‚Äôd use Claude Opus, as I‚Äôve got better results with it recently. And yes, I‚Äôm subscribed to far too many LLMs and, yes, it feels like being subcribed to too many streaming services right now! Also, I usually write for ML & AI developers but I realised a lot of people don‚Äôt know how LLMs like Claude and ChatGPT can help them with basic knowledge work so that was the rationale for this post."
  },
  {
    "objectID": "posts/llm-productivity/index.html#things-chatgpt-can-do-that-perhaps-you-dont-know-about",
    "href": "posts/llm-productivity/index.html#things-chatgpt-can-do-that-perhaps-you-dont-know-about",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "Things ChatGPT can do that perhaps you don‚Äôt know about",
    "text": "Things ChatGPT can do that perhaps you don‚Äôt know about\nLLMs offer lots of potential ‚Äúproductivity hacks‚Äù for working professionals:\n\nMeeting Summarization and Action Item Generation: After recording a meeting or providing notes, generative AI can summarize the key discussions, decisions, and action items.\nCompetitive Analysis and Market Research: By feeding generative AI tools with queries and data sources, they can conduct preliminary market research and competitive analysis, providing summaries of market trends, competitor strategies, and potential opportunities.\nAutomated Email Drafting and Management: Generative AI can help draft emails based on brief inputs, saving time on composing responses or outreach messages. For instance, by summarizing the key points you wish to communicate, the AI can generate a well-crafted email.\nProject Proposal and Report Generation: Generative AI can help draft project proposals and reports by inputting data points and objectives, significantly reducing the time required for these tasks. This includes generating structured documents with executive summaries, analyses, and conclusions based on the provided data, which can be further customized as needed.\nContent Creation and Marketing Material Development: Generative AI can assist in creating high-quality content, such as blog posts, social media content, and marketing materials, with minimal input. By providing a brief outline or key points, the AI can generate drafts that can be fine-tuned, enabling professionals to maintain an active online presence without dedicating extensive time to content creation.\n\nLet‚Äôs now look at summarization, move on to analysis, and then combine these with the better-known generative capabilities of LLMs."
  },
  {
    "objectID": "posts/llm-productivity/index.html#summarization",
    "href": "posts/llm-productivity/index.html#summarization",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "Summarization",
    "text": "Summarization\nLLMs will summarize lots of things you may not have the time to read, such as PDFs, blog posts, websites, and YouTube videos.\n\nSummarizing documents\nIf you want to summarize a document you don‚Äôt have time to read, you can upload it to ChatGPT. Here‚Äôs an example. Have a look and notice that you can get the summary in any number of forms. For example, I asked it for\n\nA basic summary\nAn executive summary appropriate for business leaders\nAn ELI5 (explain it like I‚Äôm 5) summary\n\n\n\n\nSummarizing blog posts and websites\nWe can also summarize websites such as Andrei Karpathy‚Äôs seminal Software 2.0 blog post. Note that I had to nudge ChatGPT to do this, however! Don‚Äôt be afraid to do this: it‚Äôs a conversation.\n\nWe can also take it a step further and get ChatGPT to recommend popular essays by someone we‚Äôre interested in and then summarize some of the most popular ones.\n\nIn this example, I also got ChatGPT to generate a PDF of its summaries for me, in case I wanted to read later or share.\n\n\nSummarizing meetings, YouTube videos, and so on\nYou can also summarize anything else that you have in text. One of the big time savers for many is meeting summarization and action item generation. To do this in ChatGPT, you need to get the meeting audio/video into text form:\n\nif you record meetings using Zoom, you can ‚Äúenable transcription‚Äù in Zoom;\nIf you share videos with colleagues using Slack, it will generate a transcript for you;\nYou can upload audio and/or video to services such as Descript and Otter.ai to generate transcripts.\n\nYou can then upload your transcript to Claude or ChatGPT to generate a summary and action items. You can also ask your LLM specific questions to drill down into next steps for yourself, for example!\nA couple of notes:\n\nDepending on the length of your transcript, you may need to divide it into chunks: you can even ask ChatGPT how many words it will generally accept and even negotiate with it ;)\nTranscription services, such as Otter.ai mentioned above, already offer AI-generated summaries ‚Äì this will become the norm! Currently, the most useful options I‚Äôve found for customizability involve uploading transcripts into ChatGPT but I‚Äôd be somewhat surprised if this remained the case for too long.\n\nSo how about summarizing online videos?\n\nFirst, I need to get the transcript into ChatGPT. I suppose I could rip the video and use Descript to generate the transcript. Well, I actually used to do this.\nThen I discovered a Chrome extension called Glasp that transcribes YT videos directly into instances of Claude or ChatGPT for you: go get it!"
  },
  {
    "objectID": "posts/llm-productivity/index.html#analysis-of-texts",
    "href": "posts/llm-productivity/index.html#analysis-of-texts",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "Analysis of texts",
    "text": "Analysis of texts\nNext up, I have found LLMs useful for the analysis of texts. For example, I work in early-stage startup land in an almost absurdly busy space. So I‚Äôve found using LLMs for market research and competitive analysis. I will give a toy example instead of examples from my day job."
  },
  {
    "objectID": "posts/llm-productivity/index.html#market-research-and-competitive-analysis",
    "href": "posts/llm-productivity/index.html#market-research-and-competitive-analysis",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "Market Research and Competitive Analysis",
    "text": "Market Research and Competitive Analysis\nLet‚Äôs say I wanted to start a business that provides an AI tutor for every math(s) student in the world. I told ChatGPT this and asked for help with a competitive analysis and market research.\nChatGPT came back immediately with many ideas for both, such as\n\nNotice it provided an analysis method and also suggested some competitors for us to consider. I decided to first embark on a direct competitor analysis and directed ChatGPT to perform such an analysis and provide the results to me in a table:\n\nIf you‚Äôre technically minded, also note that ChatGPT gives me the Python code that it used to generate this table, if I‚Äôd like it!\n\nI also thought it would be useful to have the analysis as a document I could share with colleagues so I asked ChatGPT to generate a spreadsheet for me, not being quite sure if it could and/or would: and it generated a .csv file! So I downloaded the .csv and put it in a Google sheet that you can find here.\nDo check out the relevant chat I had for more details, including some more market research, in which ChatGPT helps me with a back-of-the-envelope calculation to estimate the TAM (Total Addressable Market):"
  },
  {
    "objectID": "posts/llm-productivity/index.html#generation",
    "href": "posts/llm-productivity/index.html#generation",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "Generation",
    "text": "Generation\nText generation is one of the better-known capabilities of LLMs:\n\nEmail generation: give Claude or ChatGPT bullet points, and they can generate emails for you ‚Äì play around with getting them to draft emails in different tones (e.g.¬†to a manager, make it more formal, or informal)\nProject proposals and report generation: similarly, you can get LLMs to generate proposals and reports, based on talking points or even a conversation with the LLM ‚Äì if you have a specific structure for the report, such as 3 sections X, Y, and Z, with maximum 500 words each, tell it and the LLM will generally make it happen!\nContent Creation and Marketing Material Development: particularly at the ideation stage, LLMs can be used for generating copy and images for all types of content creation.\n\nI encourage you to play around with the ones you find most useful!\n\nGenerating an ad campaign\nAs a fun and somewhat dystopic illustrative example, I asked ChatGPT to create a ‚Äúmarketing campaign for a product that inserts ads in people‚Äôs dreams.‚Äù it came up with the following:\n\nI also asked it to generate some potential marketing images for me:"
  },
  {
    "objectID": "posts/llm-productivity/index.html#what-to-do-next",
    "href": "posts/llm-productivity/index.html#what-to-do-next",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "What to do next",
    "text": "What to do next\nThe next steps are simple: think about what types of tasks that LLMs could make easier for you. Start by thinking along the lines of text summary, analysis, and generation. Then have conversations with ChatGPT and/or Claude to see what‚Äôs possible!\nSeveral notes to keep in mind:\n\nMy prediction is that the types of affordances discussed here will be increasingly embedded in products: e.g.¬†you won‚Äôt need to go directly to ChatGPT but you‚Äôll be able to do such tasks directly in a Microsoft Office product;\nYou may have noticed that ChatGPT required coaxing at some points in our conversations (at one point, it even said ‚ÄúI can‚Äôt do this‚Äù, I replied ‚ÄúYes, it can‚Äù and it did!) ‚Äì so persevere with it ‚Äì it‚Äôs surprising what‚Äôs possible!\nIt is commonly accepted that ChatGPT got lazier for some time (some speculated that this happened last December and it may have been intentional as it‚Äôs when the internet itself gets lazier, with the holiday season ‚Äì Sam Altman even came out in February and said ChatGPT should be much ‚Äúless lazy now‚Äù; to this point, it‚Äôs important to note that ChatGPT has not been specifically designed for most of the tasks I‚Äôve discussed in this post, but there are so many things that are possible;\nThis space is moving rapidly: I doubt we‚Äôll be playing around with ChatGPT for a long time to achieve such tasks as discussed above; very many products will be released to solve many of these problems:\n\nwe have seen that Otter.ai summarizes transcripts;\nCopy.ai is doing interesting things for content creation and go-to-market strategies;\nMicrosoft Copilot is already incorporating a lot of the capabilities we‚Äôve covered here but don‚Äôt be fooled by thinking there‚Äôs one obvious winner ‚Äì this will likely end up more like the streaming wars;\n\nBe careful with your data! I wouldn‚Äôt currently upload any sensitive material to ChatGPT, for example: we really don‚Äôt know what OpenAI does with it; Copy.ai, for example, claims to use only LLMs that have zero-retention data policies; this space is going to be wild!\n\nSo the takeaway is simple: go play around and be more productive! Also, if you‚Äôre interested in learning about more capabilities of generative AI, check out my next blog post with Johno Whitaker on building GenAI apps that include a lot more than LLMs, such as those involving video, audio, and images.\n\nTell me what you did\nI‚Äôd be excited to hear from you about what you were able to build or even just play around with! Feel free to ping Hme on Twitter @hugobowne to let me know :)"
  },
  {
    "objectID": "posts/pierre-menard/index.html",
    "href": "posts/pierre-menard/index.html",
    "title": "ChatGPT, Author of The Quixote",
    "section": "",
    "text": "In the era of generative AI, copyright won‚Äôt be enough. In fact, it‚Äôs the wrong place to look.\nTl;dr\nIn Borges‚Äô fable Pierre Menard, Author of The Quixote, the eponymous Monsieur Menard plans to sit down and write a portion of Cervantes‚Äô Don Quixote. Not to transcribe, but re-write the epic novel word for word:\nHe first tried to do so by becoming Cervantes, learning Spanish, and forgetting all the history since Cervantes wrote Don Quixote, among other things, but then decided it would make more sense to (re)write the text as Menard himself. The narrator tells us that ‚Äúthe Cervantes text and the Menard text are verbally identical, but the second is almost infinitely richer.‚Äù Perhaps this is an inversion of the ability of Generative AI models (LLMs, text-to-image, and more) to reproduce swathes of their training data without those chunks being explicitly stored in the model and its weights: the output is verbally identical to the original but reproduced probabilistically without any of the human blood, sweat, tears, and life experience that goes into the creation of human writing and cultural production."
  },
  {
    "objectID": "posts/pierre-menard/index.html#generative-ai-has-a-plagiarism-problem",
    "href": "posts/pierre-menard/index.html#generative-ai-has-a-plagiarism-problem",
    "title": "ChatGPT, Author of The Quixote",
    "section": "Generative AI Has a Plagiarism Problem",
    "text": "Generative AI Has a Plagiarism Problem\nChatGPT, for example, doesn‚Äôt memorize its training data, per se. As Mike Loukides and Tim O‚ÄôReilly astutely point out,\n\nA model prompted to write like Shakespeare may start with the word ‚ÄúTo,‚Äù which makes it slightly more probable that it will follow that with ‚Äúbe,‚Äù which makes it slightly more probable that the next word will be ‚Äúor‚Äù ‚Äì and so forth.\n\nSo then, as it turns out, next-word prediction (and all the sauce on top) can reproduce chunks of training data. This is the basis of the NYTimes lawsuit against OpenAI. I have been able to convince ChatGPT to give me large chunks of novels that are in the public domain, such as those on Project Gutenberg, including Pride and Prejudice. Researchers are finding more and more ways to extract training data from ChatGPT and other models. As far as other types of foundation models go, recent work by Gary Marcus and Reid Southern has shown that you can use Midjourney (text-to-image) to generate images such as these1:\n\n\n[Image from here]\n\nThis seems to be emerging as a feature, not a bug, and hopefully it‚Äôs obvious to you why they called their IEEE opinion piece Generative AI Has a Visual Plagiarism Problem. And the space is moving quickly: SORA, OpenAI‚Äôs text-to-video model, is yet to be released and has already taken the world by storm."
  },
  {
    "objectID": "posts/pierre-menard/index.html#compression-transformation-hallucination-and-generation",
    "href": "posts/pierre-menard/index.html#compression-transformation-hallucination-and-generation",
    "title": "ChatGPT, Author of The Quixote",
    "section": "Compression, Transformation, Hallucination, and Generation",
    "text": "Compression, Transformation, Hallucination, and Generation\nTraining data isn‚Äôt stored in the model per se but large chunks of it are reconstructable, given the correct key (‚Äúprompt‚Äù).\nThere are lots of conversations about whether or not LLMs (and machine learning, more generally) are forms of compression or not. In many ways, they are, but they also have generative capabilities that we don‚Äôt often associate with compression.\nTed Chiang wrote a thoughtful piece for the New Yorker called ChatGPT is a Blurry JPEG of the Web that opens with the analogy of a photocopier making a slight error due to the way it compresses the digital image. It‚Äôs an interesting piece that I commend to you but one that makes me uncomfortable. To me, the analogy breaks down before it begins: firstly, LLMs don‚Äôt merely blur, but perform highly non-linear transformations, which means you can‚Äôt just squint and get a sense of the original; secondly, for the photocopier, the error is a bug, whereas, for LLMs, all errors are features. Let me explain. Or, rather, let Andrej Karpathy explain:\n\nI always struggle a bit [when] I‚Äôm asked about the ‚Äúhallucination problem‚Äù in LLMs. Because, in some sense, hallucination is all LLMs do. They are dream machines.\n\n\nWe direct their dreams with prompts. The prompts start the dream, and based on the LLM‚Äôs hazy recollection of its training documents, most of the time the result goes someplace useful.\n\n\nIt‚Äôs only when the dreams go into deemed factually incorrect territory that we label it a ‚Äúhallucination‚Äù. It looks like a bug, but it‚Äôs just the LLM doing what it always does.\n\n\nAt the other end of the extreme consider a search engine. It takes the prompt and just returns one of the most similar ‚Äútraining documents‚Äù it has in its database, verbatim. You could say that this search engine has a ‚Äúcreativity problem‚Äù - it will never respond with something new. An LLM is 100% dreaming and has the hallucination problem. A search engine is 0% dreaming and has the creativity problem.\n\nAs a side note, building products that strike balances between Search and LLMs will be a highly productive area and companies such as Perplexity AI are also doing interesting work there.\nIt‚Äôs interesting to me that, while LLMs are constantly ‚Äúhallucinating‚Äù2, they can also reproduce large chunks of training data, not just go ‚Äúsomeplace useful‚Äù, as Karpathy put it (summarization, for example). So: is the training data ‚Äústored‚Äù in the model? Well, no, not quite. But also‚Ä¶. Yes?\nLet‚Äôs say I tear up a painting into a thousand pieces and put them back together in a mosaic: is the original painting stored in the mosaic? No, unless you know how to rearrange the pieces to get the original. You need a key. And, as it turns out, there happen to be certain prompts that act as keys that _unlock _training data (for insiders, you may recognize this as extraction attacks, a form of adversarial machine learning).\nThis also has implications for whether Generative AI can create anything particularly novel: I have high hopes that it can but I think that is still yet to be demonstrated. There are also significant and serious concerns about what happens when we continually train models on the outputs of other models."
  },
  {
    "objectID": "posts/pierre-menard/index.html#implications-for-copyright-and-legitimacy-big-tech-and-informed-consent",
    "href": "posts/pierre-menard/index.html#implications-for-copyright-and-legitimacy-big-tech-and-informed-consent",
    "title": "ChatGPT, Author of The Quixote",
    "section": "Implications for Copyright and Legitimacy, Big Tech and Informed Consent",
    "text": "Implications for Copyright and Legitimacy, Big Tech and Informed Consent\nCopyright isn‚Äôt the correct paradigm to be thinking about here; legal doesn‚Äôt mean legitimate; surveillance models trained on photos of your children.\nNow I don‚Äôt think this necessarily has implications for whether LLMs are infringing copyright and whether ChatGPT is infringing that of the NYTimes, Sarah Silverman, George RR Martin, or any of us whose writing has been scraped for training data. But I also don‚Äôt think copyright is necessarily the best paradigm for thinking through whether such training and deployment should be legal or not. Firstly, copyright was created in response to the affordances of mechanical reproduction and we now live in an age of digital reproduction, distribution, and generation. It‚Äôs also about what type of society we want to live in collectively: copyright itself was originally created to incentivize certain modes of cultural production.\nEarly predecessors of modern copyright law, such as the Statute of Anne (1710) in England, were created to incentivize writers to write and to incentivize more cultural production. Up until this point, the Crown had granted exclusive rights to print certain works to the Stationers‚Äô Company, effectively creating a monopoly, and there weren‚Äôt financial incentives to write. So, even if OpenAI and their frenemies aren‚Äôt breaching copyright law, what type of cultural production are we and aren‚Äôt we incentivizing by not zooming out and looking at as many of the externalities here as possible?\nRemember the context. Actors and writers were recently striking while Netflix had an AI product manager job listing with a base salary ranging from $300K to $900K USD3. Also, note that we already live in a society where many creatives end up in advertising and marketing. These may be some of the first jobs on the chopping block due to ChatGPT and friends, particularly if macroeconomic pressure keeps leaning on us all. And that‚Äôs according to OpenAI!\n\nBack to copyright: I don‚Äôt know enough about copyright law but it seems to me as though LLMs are ‚Äútransformative‚Äù enough to have a fair use defense in the US. Also, training models doesn‚Äôt seem to me to infringe copyright because it doesn‚Äôt yet produce output! But perhaps it should infringe something: even when the collection of data is legal (which statistically it won‚Äôt entirely be for any web-scale corpus), it doesn‚Äôt mean it‚Äôs legitimate, and it definitely doesn‚Äôt mean there was informed consent.\nTo see this, let‚Äôs consider another example, that of MegaFace. In How Photos of Your Kids Are Powering Surveillance Technology, the NYTimes reported that\n\nOne day in 2005, a mother in Evanston, Ill., joined Flickr. She uploaded some pictures of her children, Chloe and Jasper. Then she more or less forgot her account existed‚Ä¶\n\n\nYears later, their faces are in a database that‚Äôs used to test and train some of the most sophisticated [facial recognition] artificial intelligence systems in the world.\n\nWhat‚Äôs more,\n\nContaining the likenesses of nearly 700,000 individuals, it has been downloaded by dozens of companies to train a new generation of face-identification algorithms, used to track protesters, surveil terrorists, spot problem gamblers, and spy on the public at large.\n\nEven in the cases where this is legal (which seem to be the vast majority of cases), it‚Äôd be tough to make an argument that it‚Äôs legitimate and even tougher to claim that there was informed consent. I also presume most people would consider it ethically dubious. I raise this example for several reasons:\n\nJust because something is legal, doesn‚Äôt mean we want it to be going forward;\nThis is illustrative of an entirely new paradigm, enabled by technology, in which vast amounts of data can be collected, processed, and used to power algorithms, models, and products, the same paradigm under which GenAI models are operating;\nIt‚Äôs a paradigm that‚Äôs baked into how a lot of Big Tech operates and we seem to accept in many forms now: but if you‚Äôd built LLMs 10, let alone 20, years ago by scraping web-scale data, this would likely be a very different conversation.\n\nI should probably also define what I mean by ‚Äúlegitimate/illegitimate‚Äù or at least point to a definition. When the Dutch East India Company ‚Äúpurchased‚Äù Manhattan from the Lenape people, Peter Minuit, who orchestrated the ‚Äúpurchase‚Äù, supposedly paid $24 worth of trinkets. That wasn‚Äôt illegal. Was it legitimate? It depends on your POV: not from mine. The Lenape didn‚Äôt have a conception of land ownership, just as we don‚Äôt yet have a serious conception of data ownership. This supposed ‚Äúpurchase‚Äù of Manhattan has resonances with uninformed consent. It‚Äôs also relevant as Big Tech is known for its extractive and colonialist practices."
  },
  {
    "objectID": "posts/pierre-menard/index.html#this-isnt-about-copyright-the-nytimes-or-openai",
    "href": "posts/pierre-menard/index.html#this-isnt-about-copyright-the-nytimes-or-openai",
    "title": "ChatGPT, Author of The Quixote",
    "section": "This isn‚Äôt about copyright, the NYTimes, or OpenAI ",
    "text": "This isn‚Äôt about copyright, the NYTimes, or OpenAI \nIt‚Äôs about what type of society you want to live in\nI think it‚Äôs entirely possible that the NYTimes and OpenAI will settle out of court: OpenAI has strong incentives to do so and the Times likely also has short-term incentives to. However, the Times has also proven itself adept at playing the long game. Don‚Äôt fall into the trap of thinking this is merely about the specific case at hand. To zoom out again, we live in a society where mainstream journalism has been carved out and gutted by the Internet, Search, and Social Media. The NYTimes is one of the last serious publications standing and they‚Äôve worked incredibly hard and cleverly in their ‚Äúdigital transformation‚Äù since the advent of the internet.4\nPlatforms such as Google have inserted themselves as middlemen between producers and consumers in a manner that has killed the business models of many of the content producers. They‚Äôre also disingenuous about what they‚Äôre doing: when the Australian Government was thinking of making Google pay news outlets that it linked to in Search, Google‚Äôs response was:\n\nNow remember, we don‚Äôt show full news articles, we just show you where you can go and help you to get there. Paying for links breaks the way search engines work, and it undermines how the web works, too. Let me try and say it another way. Imagine your friend asks for a coffee shop recommendation. So you tell them about a few nearby so they can choose one and go get a coffee. But then you get a bill to pay all the coffee shops, simply because you mentioned a few. When you put a price on linking to certain information, you break the way search engines work, and you no longer have a free and open web. We‚Äôre not against a new law, but we need it to be a fair one. Google has an alternative solution that supports journalism. It‚Äôs called Google News Showcase.\n\nLet me be clear: Google has done incredible work in ‚Äúorganizing the world‚Äôs information‚Äù but here they‚Äôre disingenuous in comparing themselves to a friend offering advice on coffee shops: friends don‚Äôt tend to have global data, AI, and infrastructural pipelines, nor are they business predicated on surveillance capitalism.\nCopyright aside, the ability of Generative AI to displace creatives is a real threat and I‚Äôm asking a real question: do we want to live in a society where there aren‚Äôt many incentives for humans to write, paint, and make music? Borges may not write today, given current incentives. If you don‚Äôt particularly care about Borges, perhaps you care about Philip K. Dick, Christopher Nolan, Salman Rushdie, or the Magic Realists, who were all influenced by his work.\nBeyond all the human aspects of cultural production, don‚Äôt we also still want to dream? Or do we also want to outsource that and have LLMs do all the dreaming for us?"
  },
  {
    "objectID": "posts/pierre-menard/index.html#notes",
    "href": "posts/pierre-menard/index.html#notes",
    "title": "ChatGPT, Author of The Quixote",
    "section": "Notes",
    "text": "Notes"
  },
  {
    "objectID": "posts/pierre-menard/index.html#footnotes",
    "href": "posts/pierre-menard/index.html#footnotes",
    "title": "ChatGPT, Author of The Quixote",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt‚Äôs ironic that, when syndicating this essay on O‚ÄôReilly Radar, we didn‚Äôt reproduce the images from Marcus‚Äô article because we didn‚Äôt want to risk violating copyright‚Äìa risk that Midjourney apparently ignores and perhaps a risk that even IEEE and the authors took on!‚Ü©Ô∏é\nI‚Äôm putting this in quotation marks as I‚Äôm still not entirely comfortable with the implications of antropomorphizing LLMs in this manner.‚Ü©Ô∏é\nMy intention isn‚Äôt to suggest that Netflix is all bad. Far from it, in fact ‚Äì Netflix has also been hugely powerful in providing a massive distribution channel to creatives across the globe. It‚Äôs complicated.‚Ü©Ô∏é\nAlso note that the outcome of this case could have significant impact for the future of OSS and open weight foundation models, something I hope to write about in future.‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/gen-ai-atomic-units/index.html",
    "href": "posts/gen-ai-atomic-units/index.html",
    "title": "Getting Started with Generative AI for Everyone",
    "section": "",
    "text": "Tl;dr\nWith the advent of Generative AI, more people than ever (technical and non-technical) can build interesting, fun, and productivity-increasing AI apps and workflows. There are several challenges:\nIn this blog post, we lay out many of the current capabilities of genAI tools, suggest ways to combine them, and spell out the genAI mindset of combining atomic units. In addition, we propose a simple protocol for building such apps and workflows:\nWhether it‚Äôs YouTube video summarization, generating images with captions, building workflow automation tools, generating email templates, or writing short stories accompanied by images, we hope that people can use this protocol to build apps and workflows that help them at work and in their daily lives.\nThis post is intended for those familiar with the basic capabilities of LLMs such as ChatGPT and Claude. For those who want to find out more about how such LLMs can be used to help with the following, check this post out:\nIt was great to co-write this post with Johno Whitaker!"
  },
  {
    "objectID": "posts/gen-ai-atomic-units/index.html#the-genai-mindset-combining-atomic-units",
    "href": "posts/gen-ai-atomic-units/index.html#the-genai-mindset-combining-atomic-units",
    "title": "Getting Started with Generative AI for Everyone",
    "section": "The GenAI mindset: combining atomic units",
    "text": "The GenAI mindset: combining atomic units\nWe recently released an episode of Vanishing Gradients about accessibility in generative AI. Both Johno and Hugo are particularly excited about how all the new tooling allows non-technical people to use machine learning and AI models through the ability to interact with them using natural language.\nThere are also new elements of how we even think about working with such tools. Consider the different mindsets of how we build machine learning, deep learning, and AI models:\n\nML mindset: how can I generate useful features for prediction?\nDL mindset: how can I express what I want in terms of some loss function to optimize?\nGenAI mindset: how can I build applications using atomic generative AI units?\n\nFor an example of the latter, consider a task Hugo does a lot of in his day job: summarizing YouTube videos (see here and here, for examples). To do this, you can break the task down into atomic units:\n\nSpeech-to-text: to get a transcript of the video;\nText-to-text: to summarize the transcript.\n\nNow anybody with differing levels of technical and hacker prowess can do this:\n\nIf you‚Äôre into writing Python code, accessing cloud compute, and playing around with foundation models, you could use OpenAI‚Äôs OSS speech-to-text Whisper model and then any number of OSS LLMs for summarization, e.g.¬†Llama2 or Mixtral;\nIf you don‚Äôt want to write any code, you could use products such as Otter.ai or Descript to get the transcription and then use Claude or ChatGPT for the summarization;\nIf you‚Äôre lazy like Hugo, you may have discovered that some legend has built a Chrome plugin called Glasp that essentially does this for you: Glasp performs the speech-to-text and pipes the result into Claude or ChatGPT, which then performs the text-to-text summarization."
  },
  {
    "objectID": "posts/gen-ai-atomic-units/index.html#whats-currently-possible-with-genai",
    "href": "posts/gen-ai-atomic-units/index.html#whats-currently-possible-with-genai",
    "title": "Getting Started with Generative AI for Everyone",
    "section": "What‚Äôs currently possible with GenAI",
    "text": "What‚Äôs currently possible with GenAI\nWe have a public awareness issue: many people don‚Äôt even know what‚Äôs currently possible and what the atomic units are! For example, you can speak to chatGPT and have it create images, which combines speech-to-text and text-to-image. So what type of models are there?\n\nText-to-text, such as ChatGPT, Claude, and so many open-source options;\nText-to-speech and speech-to-text, such as Whisper, Otter.ai, and Descript;\nText-to-image, such as Stable Diffusion, Midjourney, Pika Labs, Runway ml, and DALL¬∑E 3;\nImage-to-image, such as Runway ml;\nText-to-video, such as Stable Video Diffusion, Runway ml, and Sora;\nImage-to-video, such as Stable Video Diffusion and Runway ml;\nText-to-music, such as Suno AI.\n\nHugo generated this list using ChatGPT and you can see the full conversation for other ideas here. It‚Äôs worth mentioning that the examples above sun the gamut from free to paid to open source, so feel free to jump in and play around with all types of models. Also note that some of these types of models are fairly obvious and single-use (text-to-speech or image) while others are a lot more configurable (e.g., LLMs can be used for semi-arbitrary text transformations, such as summarization, conversation, and more)."
  },
  {
    "objectID": "posts/gen-ai-atomic-units/index.html#an-example-of-combining-atomic-ai-units",
    "href": "posts/gen-ai-atomic-units/index.html#an-example-of-combining-atomic-ai-units",
    "title": "Getting Started with Generative AI for Everyone",
    "section": "An example of combining atomic AI units",
    "text": "An example of combining atomic AI units\nIn their conversation, Johno gives a nice example: he wants to programmatically pull an image from the internet, then use a vision and text model to generate a silly quote to add to it:\n\n\n\n\n\nGet image: He first asked ChatGPT how he could use Python to pull a random high-quality photo from Unsplash ‚Äì ChatGPT gave him some code and instructions, which worked;\nGet quote: He used OpenAI‚Äôs docs and quickstart examples to get an image-to-text model to generate a quote;\nCombine quote and image: He asked ChatGPT to give him Python code to do this and it delivered!\n\nNote that Steps 1 and 3 don‚Äôt actually require any AI models but Johno cleverly used ChatGPT to give him the code for these steps.\nSo why are we telling you all of this? Well, we want to encourage everyone to experiment with all of these burgeoning tools, both for productivity and for pleasure!"
  },
  {
    "objectID": "posts/gen-ai-atomic-units/index.html#how-to-get-started-building-your-own-genai-apps-and-workflows",
    "href": "posts/gen-ai-atomic-units/index.html#how-to-get-started-building-your-own-genai-apps-and-workflows",
    "title": "Getting Started with Generative AI for Everyone",
    "section": "How to get started building your own GenAI apps and workflows",
    "text": "How to get started building your own GenAI apps and workflows\nThe protocol we suggest is as follows:\n\nIdentify a basic MVP of what you want to build (e.g.¬†YouTube video summarization, generating images with captions, building workflow automation tools, generating email templates, or writing short stories accompanied by images);\nBreak it down into atomic units;\nDecide on a tool for each atomic unit;\nStitch them together!\n\nWe also strongly encourage you to speak with an AI assistant such as ChatGPT or Claude about any of these steps also, even merely to ideate about Step 1!\nWe now suggest a few ways to get started with this process, for those who don‚Äôt code, for those who, and for those who want to chat with an AI to get some inspiration :)\nNote: Although currently we are stitching together a variety of tools and models, we are currently seeing the rise of more and more multimodal tools, which are systems or platforms that can process and integrate multiple types of data or input modalities, such as text, images, audio, and video. It‚Äôs eminently possible and perhaps likely that we‚Äôll be using such tools for many steps of this process in the future (as opposed to stitching many tools together), but the mindset will remain the same.\n\nExplore what‚Äôs possible without code on Replicate\nGo to Replicate‚Äôs explore page and, well, explore! Hugo is just looking now and it‚Äôs all so much fun:\n\nYou have a sticker maker, high-quality image generator, a way to play with Google‚Äôs Gemma model, a Mixtral assistant, a fast Whisper model, and an image-to-image model which, once you click through, shows you how to turn this image\n\nInto this!\n\n\n\nExplore what‚Äôs possible with code\nDo the same but explore HuggingFace models and HuggingFace spaces. Something you can do here is look at the code for existing spaces for inspiration - in many cases you can copy-paste (or git clone the whole space) to get a working starting point. Many of them also have Gradio demos you can play around with immediately!\n\n\nChat with ChatGPT or Claude about what‚Äôs possible\nSeriously. You saw above how Johno chatted with ChatGPT to achieve a basic task. Have a chat with an LLM about how to do things you‚Äôd like to. If you can‚Äôt think of anything, ask it to help you think of something! You can even ask it to ask you about your interests and to help you think about what you could build.\nHugo actually just played around with ChatGPT to do something along these lines and ended up writing a story and generating an image to accompany it with ChatGPT. You can check out the conversation here, if you‚Äôd like, and the resulting notebook here :)\nThere are a few things to note about the conversation Hugo had with ChatGPT here:\n\nHugo made some slight prompting errors by not being specific enough such as writing ‚Äúyes lets go through it step by step please‚Äù instead of ‚Äúlet‚Äôs start with step 1 now‚Äù;\nSeveral models ChatGPT suggested didn‚Äôt end up working! Hugo had to probe ChatGPT in order to get the correct code: this is common! Just like conversations with people, it‚Äôs not uncommon to have to ask several times (to have a conversation) to get the information you‚Äôre really looking for;\nHugo likes writing code in Jupyter notebooks so suggested to ChatGPT that they use notebooks and Python code: feel free to suggest what makes you most comfortable (but also try to push yourself!).\n\nTo the final point, a large part of the podcast conversation is about how people who don‚Äôt write code can leverage GenAI models these days. Having said that, we encourage people who don‚Äôt code to learn a little, if the feel like it, and LLMs make it easier than ever to do so.\nJensen Huang, CEO of Nvidia, ‚Äúargues that we should stop saying kids should learn to code. He argues the rise of AI means we can replace programming languages with human language prompts thus enabling everyone to be a programmer.‚Äù\n\n\n\nJensen Huang, CEO of Nvidia, argues that we should stop saying kids should learn to code. He argues the rise of AI means we can replace programming languages with human language prompts thus enabling everyone to be a programmer. AI will kill coding.pic.twitter.com/SxK9twhEby\n\n‚Äî Dare ObasanjoüêÄ (@Carnage4Life) February 24, 2024\n\n\n\nWe don‚Äôt necessarily agree with this characterization. Not everybody needs to be a software engineer but learning a bit of coding pays serious dividends and likely will in the future, even just to stitch atomic GenAI units together.\n\n\nTell us what you did\nWe‚Äôd be excited to hear from you about what you were able to build or even just play around with! Feel free to ping Hugo on Twitter @hugobowne to let him know :)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hugo's blog",
    "section": "",
    "text": "Getting Started with Generative AI for Everyone\n\n\n\n\n\n\nGenAI\n\n\nLLMs\n\n\n\nWith the advent of Generative AI, more people than ever (technical and non-technical) can build interesting, fun, and productivity-increasing AI apps and workflows. In this post, we introduce the GenAI mindset of combining atomic units to build AI-powered apps and workflows\n\n\n\n\n\nMay 28, 2024\n\n\nHugo Bowne-Anderson and Jonathan Whitaker\n\n\n\n\n\n\n\n\n\n\n\n\nBoost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started\n\n\n\n\n\n\nGenAI\n\n\nLLMs\n\n\n\nHave a 60-page PDF you don‚Äôt have time to read and want summarized? A meeting you need action items from? Or an online video you need transcribed and summarized? Would you like them to then generate a PDF, text file, or spreadsheet of the results? You can do all of this with ChatGPT.\n\n\n\n\n\nMay 28, 2024\n\n\nHugo Bowne-Anderson\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT, Author of The Quixote\n\n\n\n\n\n\nGenAI\n\n\nLLMs\n\n\n\n\n\n\n\n\n\nMar 24, 2024\n\n\nHugo Bowne-Anderson\n\n\n\n\n\n\n\n\n\n\n\n\nLights, GenAI, Action ‚Äì Building Systems with Generative Video\n\n\n\n\n\n\nGenAI\n\n\nMetaflow\n\n\n\nWe created a workflow to generate hundreds of videos with Stable Video Diffusion in one command. \n\n\n\n\n\nDec 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is Causal Inference?\n\n\n\n\n\n\nCausal inference\n\n\n\nAn Introduction for Data Scientists and Machine Learning Engineers. \n\n\n\n\n\nJul 28, 2022\n\n\n\n\n\n\nNo matching items"
  }
]
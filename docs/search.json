[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a data scientist, writer, educator & podcaster. My interests include promoting data & AI literacy/fluency, helping to spread data skills through organizations and society and lowering the barrier to entry for data science, analysis, and machine learning. I’m currently Head of Developer Relations at Outerbounds, a company committed to building infrastructure that provides a solid foundation for machine learning and AI applications of all shapes and sizes. I am also the host of the industry podcast Vanishing Gradients. Find out more here."
  },
  {
    "objectID": "posts/llm-productivity/index.html",
    "href": "posts/llm-productivity/index.html",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "",
    "text": "Tl;dr\nLarge Language Models (LLMs), such as ChatGPT and Claude, are known for their text generation and conversational abilities. But they are also good at other tasks that can help time-starved non-technical working professionals save time, such as text summarization and analysis.\nHave a 60-page PDF you don’t have time to read and want summarized? A meeting you need action items from? Or an online video you need transcribed and summarized? Would you like them to then generate a PDF, text file, or spreadsheet of the results?\nChatGPT will do these tasks for you. It can also do market research, competitive analyses, email drafting, ad campaign ideation, and much more. This blog post will take you through many such examples, including relevant conversations with ChatGPT: the goal is to give you the tools to get LLMs to do what they’re good at, freeing you up to do what you’re good at.\nNote: I used GPT-4 in ChatGPT for much of this post. If I were to rewrite it (which I might), I’d use Claude Opus, as I’ve got better results with it recently. And yes, I’m subscribed to far too many LLMs and, yes, it feels like being subcribed to too many streaming services right now! Also, I usually write for ML & AI developers but I realised a lot of people don’t know how LLMs like Claude and ChatGPT can help them with basic knowledge work so that was the rationale for this post."
  },
  {
    "objectID": "posts/llm-productivity/index.html#things-chatgpt-can-do-that-perhaps-you-dont-know-about",
    "href": "posts/llm-productivity/index.html#things-chatgpt-can-do-that-perhaps-you-dont-know-about",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "Things ChatGPT can do that perhaps you don’t know about",
    "text": "Things ChatGPT can do that perhaps you don’t know about\nLLMs offer lots of potential “productivity hacks” for working professionals:\n\nMeeting Summarization and Action Item Generation: After recording a meeting or providing notes, generative AI can summarize the key discussions, decisions, and action items.\nCompetitive Analysis and Market Research: By feeding generative AI tools with queries and data sources, they can conduct preliminary market research and competitive analysis, providing summaries of market trends, competitor strategies, and potential opportunities.\nAutomated Email Drafting and Management: Generative AI can help draft emails based on brief inputs, saving time on composing responses or outreach messages. For instance, by summarizing the key points you wish to communicate, the AI can generate a well-crafted email.\nProject Proposal and Report Generation: Generative AI can help draft project proposals and reports by inputting data points and objectives, significantly reducing the time required for these tasks. This includes generating structured documents with executive summaries, analyses, and conclusions based on the provided data, which can be further customized as needed.\nContent Creation and Marketing Material Development: Generative AI can assist in creating high-quality content, such as blog posts, social media content, and marketing materials, with minimal input. By providing a brief outline or key points, the AI can generate drafts that can be fine-tuned, enabling professionals to maintain an active online presence without dedicating extensive time to content creation.\n\nLet’s now look at summarization, move on to analysis, and then combine these with the better-known generative capabilities of LLMs."
  },
  {
    "objectID": "posts/llm-productivity/index.html#summarization",
    "href": "posts/llm-productivity/index.html#summarization",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "Summarization",
    "text": "Summarization\nLLMs will summarize lots of things you may not have the time to read, such as PDFs, blog posts, websites, and YouTube videos.\n\nSummarizing documents\nIf you want to summarize a document you don’t have time to read, you can upload it to ChatGPT. Here’s an example. Have a look and notice that you can get the summary in any number of forms. For example, I asked it for\n\nA basic summary\nAn executive summary appropriate for business leaders\nAn ELI5 (explain it like I’m 5) summary\n\n\n\n\nSummarizing blog posts and websites\nWe can also summarize websites such as Andrei Karpathy’s seminal Software 2.0 blog post. Note that I had to nudge ChatGPT to do this, however! Don’t be afraid to do this: it’s a conversation.\n\nWe can also take it a step further and get ChatGPT to recommend popular essays by someone we’re interested in and then summarize some of the most popular ones.\n\nIn this example, I also got ChatGPT to generate a PDF of its summaries for me, in case I wanted to read later or share.\n\n\nSummarizing meetings, YouTube videos, and so on\nYou can also summarize anything else that you have in text. One of the big time savers for many is meeting summarization and action item generation. To do this in ChatGPT, you need to get the meeting audio/video into text form:\n\nif you record meetings using Zoom, you can “enable transcription” in Zoom;\nIf you share videos with colleagues using Slack, it will generate a transcript for you;\nYou can upload audio and/or video to services such as Descript and Otter.ai to generate transcripts.\n\nYou can then upload your transcript to Claude or ChatGPT to generate a summary and action items. You can also ask your LLM specific questions to drill down into next steps for yourself, for example!\nA couple of notes:\n\nDepending on the length of your transcript, you may need to divide it into chunks: you can even ask ChatGPT how many words it will generally accept and even negotiate with it ;)\nTranscription services, such as Otter.ai mentioned above, already offer AI-generated summaries – this will become the norm! Currently, the most useful options I’ve found for customizability involve uploading transcripts into ChatGPT but I’d be somewhat surprised if this remained the case for too long.\n\nSo how about summarizing online videos?\n\nFirst, I need to get the transcript into ChatGPT. I suppose I could rip the video and use Descript to generate the transcript. Well, I actually used to do this.\nThen I discovered a Chrome extension called Glasp that transcribes YT videos directly into instances of Claude or ChatGPT for you: go get it!"
  },
  {
    "objectID": "posts/llm-productivity/index.html#analysis-of-texts",
    "href": "posts/llm-productivity/index.html#analysis-of-texts",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "Analysis of texts",
    "text": "Analysis of texts\nNext up, I have found LLMs useful for the analysis of texts. For example, I work in early-stage startup land in an almost absurdly busy space. So I’ve found using LLMs for market research and competitive analysis. I will give a toy example instead of examples from my day job."
  },
  {
    "objectID": "posts/llm-productivity/index.html#market-research-and-competitive-analysis",
    "href": "posts/llm-productivity/index.html#market-research-and-competitive-analysis",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "Market Research and Competitive Analysis",
    "text": "Market Research and Competitive Analysis\nLet’s say I wanted to start a business that provides an AI tutor for every math(s) student in the world. I told ChatGPT this and asked for help with a competitive analysis and market research.\nChatGPT came back immediately with many ideas for both, such as\n\nNotice it provided an analysis method and also suggested some competitors for us to consider. I decided to first embark on a direct competitor analysis and directed ChatGPT to perform such an analysis and provide the results to me in a table:\n\nIf you’re technically minded, also note that ChatGPT gives me the Python code that it used to generate this table, if I’d like it!\n\nI also thought it would be useful to have the analysis as a document I could share with colleagues so I asked ChatGPT to generate a spreadsheet for me, not being quite sure if it could and/or would: and it generated a .csv file! So I downloaded the .csv and put it in a Google sheet that you can find here.\nDo check out the relevant chat I had for more details, including some more market research, in which ChatGPT helps me with a back-of-the-envelope calculation to estimate the TAM (Total Addressable Market):"
  },
  {
    "objectID": "posts/llm-productivity/index.html#generation",
    "href": "posts/llm-productivity/index.html#generation",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "Generation",
    "text": "Generation\nText generation is one of the better-known capabilities of LLMs:\n\nEmail generation: give Claude or ChatGPT bullet points, and they can generate emails for you – play around with getting them to draft emails in different tones (e.g. to a manager, make it more formal, or informal)\nProject proposals and report generation: similarly, you can get LLMs to generate proposals and reports, based on talking points or even a conversation with the LLM – if you have a specific structure for the report, such as 3 sections X, Y, and Z, with maximum 500 words each, tell it and the LLM will generally make it happen!\nContent Creation and Marketing Material Development: particularly at the ideation stage, LLMs can be used for generating copy and images for all types of content creation.\n\nI encourage you to play around with the ones you find most useful!\n\nGenerating an ad campaign\nAs a fun and somewhat dystopic illustrative example, I asked ChatGPT to create a “marketing campaign for a product that inserts ads in people’s dreams.” it came up with the following:\n\nI also asked it to generate some potential marketing images for me:"
  },
  {
    "objectID": "posts/llm-productivity/index.html#what-to-do-next",
    "href": "posts/llm-productivity/index.html#what-to-do-next",
    "title": "Boost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started",
    "section": "What to do next",
    "text": "What to do next\nThe next steps are simple: think about what types of tasks that LLMs could make easier for you. Start by thinking along the lines of text summary, analysis, and generation. Then have conversations with ChatGPT and/or Claude to see what’s possible!\nSeveral notes to keep in mind:\n\nMy prediction is that the types of affordances discussed here will be increasingly embedded in products: e.g. you won’t need to go directly to ChatGPT but you’ll be able to do such tasks directly in a Microsoft Office product;\nYou may have noticed that ChatGPT required coaxing at some points in our conversations (at one point, it even said “I can’t do this”, I replied “Yes, it can” and it did!) – so persevere with it – it’s surprising what’s possible!\nIt is commonly accepted that ChatGPT got lazier for some time (some speculated that this happened last December and it may have been intentional as it’s when the internet itself gets lazier, with the holiday season – Sam Altman even came out in February and said ChatGPT should be much “less lazy now”; to this point, it’s important to note that ChatGPT has not been specifically designed for most of the tasks I’ve discussed in this post, but there are so many things that are possible;\nThis space is moving rapidly: I doubt we’ll be playing around with ChatGPT for a long time to achieve such tasks as discussed above; very many products will be released to solve many of these problems:\n\nwe have seen that Otter.ai summarizes transcripts;\nCopy.ai is doing interesting things for content creation and go-to-market strategies;\nMicrosoft Copilot is already incorporating a lot of the capabilities we’ve covered here but don’t be fooled by thinking there’s one obvious winner – this will likely end up more like the streaming wars;\n\nBe careful with your data! I wouldn’t currently upload any sensitive material to ChatGPT, for example: we really don’t know what OpenAI does with it; Copy.ai, for example, claims to use only LLMs that have zero-retention data policies; this space is going to be wild!\n\nSo the takeaway is simple: go play around and be more productive! Also, if you’re interested in learning about more capabilities of generative AI, check out my next blog post with Johno Whitaker on building GenAI apps that include a lot more than LLMs, such as those involving video, audio, and images.\n\nTell me what you did\nI’d be excited to hear from you about what you were able to build or even just play around with! Feel free to ping Hme on Twitter @hugobowne to let me know :)"
  },
  {
    "objectID": "posts/pierre-menard/index.html",
    "href": "posts/pierre-menard/index.html",
    "title": "ChatGPT, Author of The Quixote",
    "section": "",
    "text": "In the era of generative AI, copyright won’t be enough. In fact, it’s the wrong place to look.\nTl;dr\nIn Borges’ fable Pierre Menard, Author of The Quixote, the eponymous Monsieur Menard plans to sit down and write a portion of Cervantes’ Don Quixote. Not to transcribe, but re-write the epic novel word for word:\nHe first tried to do so by becoming Cervantes, learning Spanish, and forgetting all the history since Cervantes wrote Don Quixote, among other things, but then decided it would make more sense to (re)write the text as Menard himself. The narrator tells us that “the Cervantes text and the Menard text are verbally identical, but the second is almost infinitely richer.” Perhaps this is an inversion of the ability of Generative AI models (LLMs, text-to-image, and more) to reproduce swathes of their training data without those chunks being explicitly stored in the model and its weights: the output is verbally identical to the original but reproduced probabilistically without any of the human blood, sweat, tears, and life experience that goes into the creation of human writing and cultural production."
  },
  {
    "objectID": "posts/pierre-menard/index.html#generative-ai-has-a-plagiarism-problem",
    "href": "posts/pierre-menard/index.html#generative-ai-has-a-plagiarism-problem",
    "title": "ChatGPT, Author of The Quixote",
    "section": "Generative AI Has a Plagiarism Problem",
    "text": "Generative AI Has a Plagiarism Problem\nChatGPT, for example, doesn’t memorize its training data, per se. As Mike Loukides and Tim O’Reilly astutely point out,\n\nA model prompted to write like Shakespeare may start with the word “To,” which makes it slightly more probable that it will follow that with “be,” which makes it slightly more probable that the next word will be “or” – and so forth.\n\nSo then, as it turns out, next-word prediction (and all the sauce on top) can reproduce chunks of training data. This is the basis of the NYTimes lawsuit against OpenAI. I have been able to convince ChatGPT to give me large chunks of novels that are in the public domain, such as those on Project Gutenberg, including Pride and Prejudice. Researchers are finding more and more ways to extract training data from ChatGPT and other models. As far as other types of foundation models go, recent work by Gary Marcus and Reid Southern has shown that you can use Midjourney (text-to-image) to generate images such as these1:\n\n\n[Image from here]\n\nThis seems to be emerging as a feature, not a bug, and hopefully it’s obvious to you why they called their IEEE opinion piece Generative AI Has a Visual Plagiarism Problem. And the space is moving quickly: SORA, OpenAI’s text-to-video model, is yet to be released and has already taken the world by storm."
  },
  {
    "objectID": "posts/pierre-menard/index.html#compression-transformation-hallucination-and-generation",
    "href": "posts/pierre-menard/index.html#compression-transformation-hallucination-and-generation",
    "title": "ChatGPT, Author of The Quixote",
    "section": "Compression, Transformation, Hallucination, and Generation",
    "text": "Compression, Transformation, Hallucination, and Generation\nTraining data isn’t stored in the model per se but large chunks of it are reconstructable, given the correct key (“prompt”).\nThere are lots of conversations about whether or not LLMs (and machine learning, more generally) are forms of compression or not. In many ways, they are, but they also have generative capabilities that we don’t often associate with compression.\nTed Chiang wrote a thoughtful piece for the New Yorker called ChatGPT is a Blurry JPEG of the Web that opens with the analogy of a photocopier making a slight error due to the way it compresses the digital image. It’s an interesting piece that I commend to you but one that makes me uncomfortable. To me, the analogy breaks down before it begins: firstly, LLMs don’t merely blur, but perform highly non-linear transformations, which means you can’t just squint and get a sense of the original; secondly, for the photocopier, the error is a bug, whereas, for LLMs, all errors are features. Let me explain. Or, rather, let Andrej Karpathy explain:\n\nI always struggle a bit [when] I’m asked about the “hallucination problem” in LLMs. Because, in some sense, hallucination is all LLMs do. They are dream machines.\n\n\nWe direct their dreams with prompts. The prompts start the dream, and based on the LLM’s hazy recollection of its training documents, most of the time the result goes someplace useful.\n\n\nIt’s only when the dreams go into deemed factually incorrect territory that we label it a “hallucination”. It looks like a bug, but it’s just the LLM doing what it always does.\n\n\nAt the other end of the extreme consider a search engine. It takes the prompt and just returns one of the most similar “training documents” it has in its database, verbatim. You could say that this search engine has a “creativity problem” - it will never respond with something new. An LLM is 100% dreaming and has the hallucination problem. A search engine is 0% dreaming and has the creativity problem.\n\nAs a side note, building products that strike balances between Search and LLMs will be a highly productive area and companies such as Perplexity AI are also doing interesting work there.\nIt’s interesting to me that, while LLMs are constantly “hallucinating”2, they can also reproduce large chunks of training data, not just go “someplace useful”, as Karpathy put it (summarization, for example). So: is the training data “stored” in the model? Well, no, not quite. But also…. Yes?\nLet’s say I tear up a painting into a thousand pieces and put them back together in a mosaic: is the original painting stored in the mosaic? No, unless you know how to rearrange the pieces to get the original. You need a key. And, as it turns out, there happen to be certain prompts that act as keys that _unlock _training data (for insiders, you may recognize this as extraction attacks, a form of adversarial machine learning).\nThis also has implications for whether Generative AI can create anything particularly novel: I have high hopes that it can but I think that is still yet to be demonstrated. There are also significant and serious concerns about what happens when we continually train models on the outputs of other models."
  },
  {
    "objectID": "posts/pierre-menard/index.html#implications-for-copyright-and-legitimacy-big-tech-and-informed-consent",
    "href": "posts/pierre-menard/index.html#implications-for-copyright-and-legitimacy-big-tech-and-informed-consent",
    "title": "ChatGPT, Author of The Quixote",
    "section": "Implications for Copyright and Legitimacy, Big Tech and Informed Consent",
    "text": "Implications for Copyright and Legitimacy, Big Tech and Informed Consent\nCopyright isn’t the correct paradigm to be thinking about here; legal doesn’t mean legitimate; surveillance models trained on photos of your children.\nNow I don’t think this necessarily has implications for whether LLMs are infringing copyright and whether ChatGPT is infringing that of the NYTimes, Sarah Silverman, George RR Martin, or any of us whose writing has been scraped for training data. But I also don’t think copyright is necessarily the best paradigm for thinking through whether such training and deployment should be legal or not. Firstly, copyright was created in response to the affordances of mechanical reproduction and we now live in an age of digital reproduction, distribution, and generation. It’s also about what type of society we want to live in collectively: copyright itself was originally created to incentivize certain modes of cultural production.\nEarly predecessors of modern copyright law, such as the Statute of Anne (1710) in England, were created to incentivize writers to write and to incentivize more cultural production. Up until this point, the Crown had granted exclusive rights to print certain works to the Stationers’ Company, effectively creating a monopoly, and there weren’t financial incentives to write. So, even if OpenAI and their frenemies aren’t breaching copyright law, what type of cultural production are we and aren’t we incentivizing by not zooming out and looking at as many of the externalities here as possible?\nRemember the context. Actors and writers were recently striking while Netflix had an AI product manager job listing with a base salary ranging from $300K to $900K USD3. Also, note that we already live in a society where many creatives end up in advertising and marketing. These may be some of the first jobs on the chopping block due to ChatGPT and friends, particularly if macroeconomic pressure keeps leaning on us all. And that’s according to OpenAI!\n\nBack to copyright: I don’t know enough about copyright law but it seems to me as though LLMs are “transformative” enough to have a fair use defense in the US. Also, training models doesn’t seem to me to infringe copyright because it doesn’t yet produce output! But perhaps it should infringe something: even when the collection of data is legal (which statistically it won’t entirely be for any web-scale corpus), it doesn’t mean it’s legitimate, and it definitely doesn’t mean there was informed consent.\nTo see this, let’s consider another example, that of MegaFace. In How Photos of Your Kids Are Powering Surveillance Technology, the NYTimes reported that\n\nOne day in 2005, a mother in Evanston, Ill., joined Flickr. She uploaded some pictures of her children, Chloe and Jasper. Then she more or less forgot her account existed…\n\n\nYears later, their faces are in a database that’s used to test and train some of the most sophisticated [facial recognition] artificial intelligence systems in the world.\n\nWhat’s more,\n\nContaining the likenesses of nearly 700,000 individuals, it has been downloaded by dozens of companies to train a new generation of face-identification algorithms, used to track protesters, surveil terrorists, spot problem gamblers, and spy on the public at large.\n\nEven in the cases where this is legal (which seem to be the vast majority of cases), it’d be tough to make an argument that it’s legitimate and even tougher to claim that there was informed consent. I also presume most people would consider it ethically dubious. I raise this example for several reasons:\n\nJust because something is legal, doesn’t mean we want it to be going forward;\nThis is illustrative of an entirely new paradigm, enabled by technology, in which vast amounts of data can be collected, processed, and used to power algorithms, models, and products, the same paradigm under which GenAI models are operating;\nIt’s a paradigm that’s baked into how a lot of Big Tech operates and we seem to accept in many forms now: but if you’d built LLMs 10, let alone 20, years ago by scraping web-scale data, this would likely be a very different conversation.\n\nI should probably also define what I mean by “legitimate/illegitimate” or at least point to a definition. When the Dutch East India Company “purchased” Manhattan from the Lenape people, Peter Minuit, who orchestrated the “purchase”, supposedly paid $24 worth of trinkets. That wasn’t illegal. Was it legitimate? It depends on your POV: not from mine. The Lenape didn’t have a conception of land ownership, just as we don’t yet have a serious conception of data ownership. This supposed “purchase” of Manhattan has resonances with uninformed consent. It’s also relevant as Big Tech is known for its extractive and colonialist practices."
  },
  {
    "objectID": "posts/pierre-menard/index.html#this-isnt-about-copyright-the-nytimes-or-openai",
    "href": "posts/pierre-menard/index.html#this-isnt-about-copyright-the-nytimes-or-openai",
    "title": "ChatGPT, Author of The Quixote",
    "section": "This isn’t about copyright, the NYTimes, or OpenAI ",
    "text": "This isn’t about copyright, the NYTimes, or OpenAI \nIt’s about what type of society you want to live in\nI think it’s entirely possible that the NYTimes and OpenAI will settle out of court: OpenAI has strong incentives to do so and the Times likely also has short-term incentives to. However, the Times has also proven itself adept at playing the long game. Don’t fall into the trap of thinking this is merely about the specific case at hand. To zoom out again, we live in a society where mainstream journalism has been carved out and gutted by the Internet, Search, and Social Media. The NYTimes is one of the last serious publications standing and they’ve worked incredibly hard and cleverly in their “digital transformation” since the advent of the internet.4\nPlatforms such as Google have inserted themselves as middlemen between producers and consumers in a manner that has killed the business models of many of the content producers. They’re also disingenuous about what they’re doing: when the Australian Government was thinking of making Google pay news outlets that it linked to in Search, Google’s response was:\n\nNow remember, we don’t show full news articles, we just show you where you can go and help you to get there. Paying for links breaks the way search engines work, and it undermines how the web works, too. Let me try and say it another way. Imagine your friend asks for a coffee shop recommendation. So you tell them about a few nearby so they can choose one and go get a coffee. But then you get a bill to pay all the coffee shops, simply because you mentioned a few. When you put a price on linking to certain information, you break the way search engines work, and you no longer have a free and open web. We’re not against a new law, but we need it to be a fair one. Google has an alternative solution that supports journalism. It’s called Google News Showcase.\n\nLet me be clear: Google has done incredible work in “organizing the world’s information” but here they’re disingenuous in comparing themselves to a friend offering advice on coffee shops: friends don’t tend to have global data, AI, and infrastructural pipelines, nor are they business predicated on surveillance capitalism.\nCopyright aside, the ability of Generative AI to displace creatives is a real threat and I’m asking a real question: do we want to live in a society where there aren’t many incentives for humans to write, paint, and make music? Borges may not write today, given current incentives. If you don’t particularly care about Borges, perhaps you care about Philip K. Dick, Christopher Nolan, Salman Rushdie, or the Magic Realists, who were all influenced by his work.\nBeyond all the human aspects of cultural production, don’t we also still want to dream? Or do we also want to outsource that and have LLMs do all the dreaming for us?"
  },
  {
    "objectID": "posts/pierre-menard/index.html#notes",
    "href": "posts/pierre-menard/index.html#notes",
    "title": "ChatGPT, Author of The Quixote",
    "section": "Notes",
    "text": "Notes"
  },
  {
    "objectID": "posts/pierre-menard/index.html#footnotes",
    "href": "posts/pierre-menard/index.html#footnotes",
    "title": "ChatGPT, Author of The Quixote",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt’s ironic that, when syndicating this essay on O’Reilly Radar, we didn’t reproduce the images from Marcus’ article because we didn’t want to risk violating copyright–a risk that Midjourney apparently ignores and perhaps a risk that even IEEE and the authors took on!↩︎\nI’m putting this in quotation marks as I’m still not entirely comfortable with the implications of antropomorphizing LLMs in this manner.↩︎\nMy intention isn’t to suggest that Netflix is all bad. Far from it, in fact – Netflix has also been hugely powerful in providing a massive distribution channel to creatives across the globe. It’s complicated.↩︎\nAlso note that the outcome of this case could have significant impact for the future of OSS and open weight foundation models, something I hope to write about in future.↩︎"
  },
  {
    "objectID": "posts/gen-ai-atomic-units/index.html",
    "href": "posts/gen-ai-atomic-units/index.html",
    "title": "Getting Started with Generative AI for Everyone",
    "section": "",
    "text": "Tl;dr\nWith the advent of Generative AI, more people than ever (technical and non-technical) can build interesting, fun, and productivity-increasing AI apps and workflows. There are several challenges:\nIn this blog post, we lay out many of the current capabilities of genAI tools, suggest ways to combine them, and spell out the genAI mindset of combining atomic units. In addition, we propose a simple protocol for building such apps and workflows:\nWhether it’s YouTube video summarization, generating images with captions, building workflow automation tools, generating email templates, or writing short stories accompanied by images, we hope that people can use this protocol to build apps and workflows that help them at work and in their daily lives.\nThis post is intended for those familiar with the basic capabilities of LLMs such as ChatGPT and Claude. For those who want to find out more about how such LLMs can be used to help with the following, check this post out:\nIt was great to co-write this post with Johno Whitaker!"
  },
  {
    "objectID": "posts/gen-ai-atomic-units/index.html#the-genai-mindset-combining-atomic-units",
    "href": "posts/gen-ai-atomic-units/index.html#the-genai-mindset-combining-atomic-units",
    "title": "Getting Started with Generative AI for Everyone",
    "section": "The GenAI mindset: combining atomic units",
    "text": "The GenAI mindset: combining atomic units\nWe recently released an episode of Vanishing Gradients about accessibility in generative AI. Both Johno and Hugo are particularly excited about how all the new tooling allows non-technical people to use machine learning and AI models through the ability to interact with them using natural language.\nThere are also new elements of how we even think about working with such tools. Consider the different mindsets of how we build machine learning, deep learning, and AI models:\n\nML mindset: how can I generate useful features for prediction?\nDL mindset: how can I express what I want in terms of some loss function to optimize?\nGenAI mindset: how can I build applications using atomic generative AI units?\n\nFor an example of the latter, consider a task Hugo does a lot of in his day job: summarizing YouTube videos (see here and here, for examples). To do this, you can break the task down into atomic units:\n\nSpeech-to-text: to get a transcript of the video;\nText-to-text: to summarize the transcript.\n\nNow anybody with differing levels of technical and hacker prowess can do this:\n\nIf you’re into writing Python code, accessing cloud compute, and playing around with foundation models, you could use OpenAI’s OSS speech-to-text Whisper model and then any number of OSS LLMs for summarization, e.g. Llama2 or Mixtral;\nIf you don’t want to write any code, you could use products such as Otter.ai or Descript to get the transcription and then use Claude or ChatGPT for the summarization;\nIf you’re lazy like Hugo, you may have discovered that some legend has built a Chrome plugin called Glasp that essentially does this for you: Glasp performs the speech-to-text and pipes the result into Claude or ChatGPT, which then performs the text-to-text summarization."
  },
  {
    "objectID": "posts/gen-ai-atomic-units/index.html#whats-currently-possible-with-genai",
    "href": "posts/gen-ai-atomic-units/index.html#whats-currently-possible-with-genai",
    "title": "Getting Started with Generative AI for Everyone",
    "section": "What’s currently possible with GenAI",
    "text": "What’s currently possible with GenAI\nWe have a public awareness issue: many people don’t even know what’s currently possible and what the atomic units are! For example, you can speak to chatGPT and have it create images, which combines speech-to-text and text-to-image. So what type of models are there?\n\nText-to-text, such as ChatGPT, Claude, and so many open-source options;\nText-to-speech and speech-to-text, such as Whisper, Otter.ai, and Descript;\nText-to-image, such as Stable Diffusion, Midjourney, Pika Labs, Runway ml, and DALL·E 3;\nImage-to-image, such as Runway ml;\nText-to-video, such as Stable Video Diffusion, Runway ml, and Sora;\nImage-to-video, such as Stable Video Diffusion and Runway ml;\nText-to-music, such as Suno AI.\n\nHugo generated this list using ChatGPT and you can see the full conversation for other ideas here. It’s worth mentioning that the examples above sun the gamut from free to paid to open source, so feel free to jump in and play around with all types of models. Also note that some of these types of models are fairly obvious and single-use (text-to-speech or image) while others are a lot more configurable (e.g., LLMs can be used for semi-arbitrary text transformations, such as summarization, conversation, and more)."
  },
  {
    "objectID": "posts/gen-ai-atomic-units/index.html#an-example-of-combining-atomic-ai-units",
    "href": "posts/gen-ai-atomic-units/index.html#an-example-of-combining-atomic-ai-units",
    "title": "Getting Started with Generative AI for Everyone",
    "section": "An example of combining atomic AI units",
    "text": "An example of combining atomic AI units\nIn their conversation, Johno gives a nice example: he wants to programmatically pull an image from the internet, then use a vision and text model to generate a silly quote to add to it:\n\n\n\n\n\nGet image: He first asked ChatGPT how he could use Python to pull a random high-quality photo from Unsplash – ChatGPT gave him some code and instructions, which worked;\nGet quote: He used OpenAI’s docs and quickstart examples to get an image-to-text model to generate a quote;\nCombine quote and image: He asked ChatGPT to give him Python code to do this and it delivered!\n\nNote that Steps 1 and 3 don’t actually require any AI models but Johno cleverly used ChatGPT to give him the code for these steps.\nSo why are we telling you all of this? Well, we want to encourage everyone to experiment with all of these burgeoning tools, both for productivity and for pleasure!"
  },
  {
    "objectID": "posts/gen-ai-atomic-units/index.html#how-to-get-started-building-your-own-genai-apps-and-workflows",
    "href": "posts/gen-ai-atomic-units/index.html#how-to-get-started-building-your-own-genai-apps-and-workflows",
    "title": "Getting Started with Generative AI for Everyone",
    "section": "How to get started building your own GenAI apps and workflows",
    "text": "How to get started building your own GenAI apps and workflows\nThe protocol we suggest is as follows:\n\nIdentify a basic MVP of what you want to build (e.g. YouTube video summarization, generating images with captions, building workflow automation tools, generating email templates, or writing short stories accompanied by images);\nBreak it down into atomic units;\nDecide on a tool for each atomic unit;\nStitch them together!\n\nWe also strongly encourage you to speak with an AI assistant such as ChatGPT or Claude about any of these steps also, even merely to ideate about Step 1!\nWe now suggest a few ways to get started with this process, for those who don’t code, for those who, and for those who want to chat with an AI to get some inspiration :)\nNote: Although currently we are stitching together a variety of tools and models, we are currently seeing the rise of more and more multimodal tools, which are systems or platforms that can process and integrate multiple types of data or input modalities, such as text, images, audio, and video. It’s eminently possible and perhaps likely that we’ll be using such tools for many steps of this process in the future (as opposed to stitching many tools together), but the mindset will remain the same.\n\nExplore what’s possible without code on Replicate\nGo to Replicate’s explore page and, well, explore! Hugo is just looking now and it’s all so much fun:\n\nYou have a sticker maker, high-quality image generator, a way to play with Google’s Gemma model, a Mixtral assistant, a fast Whisper model, and an image-to-image model which, once you click through, shows you how to turn this image\n\nInto this!\n\n\n\nExplore what’s possible with code\nDo the same but explore HuggingFace models and HuggingFace spaces. Something you can do here is look at the code for existing spaces for inspiration - in many cases you can copy-paste (or git clone the whole space) to get a working starting point. Many of them also have Gradio demos you can play around with immediately!\n\n\nChat with ChatGPT or Claude about what’s possible\nSeriously. You saw above how Johno chatted with ChatGPT to achieve a basic task. Have a chat with an LLM about how to do things you’d like to. If you can’t think of anything, ask it to help you think of something! You can even ask it to ask you about your interests and to help you think about what you could build.\nHugo actually just played around with ChatGPT to do something along these lines and ended up writing a story and generating an image to accompany it with ChatGPT. You can check out the conversation here, if you’d like, and the resulting notebook here :)\nThere are a few things to note about the conversation Hugo had with ChatGPT here:\n\nHugo made some slight prompting errors by not being specific enough such as writing “yes lets go through it step by step please” instead of “let’s start with step 1 now”;\nSeveral models ChatGPT suggested didn’t end up working! Hugo had to probe ChatGPT in order to get the correct code: this is common! Just like conversations with people, it’s not uncommon to have to ask several times (to have a conversation) to get the information you’re really looking for;\nHugo likes writing code in Jupyter notebooks so suggested to ChatGPT that they use notebooks and Python code: feel free to suggest what makes you most comfortable (but also try to push yourself!).\n\nTo the final point, a large part of the podcast conversation is about how people who don’t write code can leverage GenAI models these days. Having said that, we encourage people who don’t code to learn a little, if the feel like it, and LLMs make it easier than ever to do so.\nJensen Huang, CEO of Nvidia, “argues that we should stop saying kids should learn to code. He argues the rise of AI means we can replace programming languages with human language prompts thus enabling everyone to be a programmer.”\n\n\n\nJensen Huang, CEO of Nvidia, argues that we should stop saying kids should learn to code. He argues the rise of AI means we can replace programming languages with human language prompts thus enabling everyone to be a programmer. AI will kill coding.pic.twitter.com/SxK9twhEby\n\n— Dare Obasanjo🐀 (@Carnage4Life) February 24, 2024\n\n\n\nWe don’t necessarily agree with this characterization. Not everybody needs to be a software engineer but learning a bit of coding pays serious dividends and likely will in the future, even just to stitch atomic GenAI units together.\n\n\nTell us what you did\nWe’d be excited to hear from you about what you were able to build or even just play around with! Feel free to ping Hugo on Twitter @hugobowne to let him know :)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hugo's blog",
    "section": "",
    "text": "Getting Started with Generative AI for Everyone\n\n\n\n\n\n\nGenAI\n\n\nLLMs\n\n\n\nWith the advent of Generative AI, more people than ever (technical and non-technical) can build interesting, fun, and productivity-increasing AI apps and workflows. In this post, we introduce the GenAI mindset of combining atomic units to build AI-powered apps and workflows\n\n\n\n\n\nMay 28, 2024\n\n\nHugo Bowne-Anderson and Jonathan Whitaker\n\n\n\n\n\n\n\n\n\n\n\n\nBoost Your Productivity with ChatGPT in 2024: Simple Steps to Get Started\n\n\n\n\n\n\nGenAI\n\n\nLLMs\n\n\n\nHave a 60-page PDF you don’t have time to read and want summarized? A meeting you need action items from? Or an online video you need transcribed and summarized? Would you like them to then generate a PDF, text file, or spreadsheet of the results? You can do all of this with ChatGPT.\n\n\n\n\n\nMay 28, 2024\n\n\nHugo Bowne-Anderson\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT, Author of The Quixote\n\n\n\n\n\n\nGenAI\n\n\nLLMs\n\n\n\n\n\n\n\n\n\nMar 24, 2024\n\n\nHugo Bowne-Anderson\n\n\n\n\n\n\n\n\n\n\n\n\nLights, GenAI, Action – Building Systems with Generative Video\n\n\n\n\n\n\nGenAI\n\n\nMetaflow\n\n\n\nWe created a workflow to generate hundreds of videos with Stable Video Diffusion in one command. \n\n\n\n\n\nDec 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is Causal Inference?\n\n\n\n\n\n\nCausal inference\n\n\n\nAn Introduction for Data Scientists and Machine Learning Engineers. \n\n\n\n\n\nJul 28, 2022\n\n\n\n\n\n\nNo matching items"
  }
]